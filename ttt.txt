//
//
//
////void testTracker(){
////    cv::Mat rgb1=cv::imread("/home/guangfu/Documents/r1.png");
////    cv::Mat rgb2=cv::imread("/home/guangfu/Documents/r2.png");
////    cv::Mat d1=cv::imread("/home/guangfu/Documents/d1.png",-1);
////    cv::Mat d2=cv::imread("/home/guangfu/Documents/d2.png",-1);
////
////    Tracking* tracker=Tracking::createTrackingTool();
////
////    std::chrono::time_point<std::chrono::steady_clock> s1 = std::chrono::steady_clock::now();
////
////    double t1=0.0f;
////    tracker->setImagePairs(rgb1,d1,t1);
////    tracker->iterationForPose();
////
////    std::chrono::time_point<std::chrono::steady_clock> e1 = std::chrono::steady_clock::now();
////    std::cout << "first frame takes: " << std::chrono::duration_cast<std::chrono::milliseconds>(e1-s1).count() << "ms" << std::endl;
////
////    std::chrono::time_point<std::chrono::steady_clock> s2 = std::chrono::steady_clock::now();
////
////    double t2=1.0f;
////
////    tracker->setImagePairs(rgb2,d2,t2);
////    Eigen::Matrix4f res2=tracker->iterationForPose();
////
////    std::chrono::time_point<std::chrono::steady_clock> e2 = std::chrono::steady_clock::now();
////    std::cout << "second frame takes: " << std::chrono::duration_cast<std::chrono::milliseconds>(e2-s2).count() << "ms" << std::endl;
////    cout<<res2<<endl;
////
////}
//

//#include "sensor.h"
//#include <iostream>
//
//
//int main()
//{
//
//    //sensor* sensor_=sensor::createSensor();
//
//    cv::Mat rg=cv::imread("/home/guangfu/Documents/r1.png");
//
//
//    //cv::imshow("258",rg);
//
//    //kinect1* k1=new kinect1();
////    Freenect::Freenect freenect;
////    MyFreenectDevice* device=&freenect.createDevice<MyFreenectDevice>(0);
////    device->startVideo();
////    device->startDepth();
////
////    cv::Mat rgb=cv::Mat(cv::Size(640, 480), CV_8UC3);;
////    cv::Mat dep=cv::Mat(cv::Size(640, 480), CV_16UC1);
////
////    device->getVideo(rgb);
////    //device->getDepth(dep);
////
////    cv::imshow("iii",rgb);
////
////    //cv::imshow("1234",dep);
////
////    device->getDepth(dep);
////
////    cv::imshow("11121",dep);
////
////    for(int i=0;i<100;i++){
////
////        cout<<dep.at<ushort>(100,i)<<endl;
////    }
////
////    device->stopVideo();
////    device->stopDepth();
//    cv::waitKey(0);
//
//    std::cin.get();
//    return 0;
//}
//
//
//
//
//
///*
// * This file is part of the OpenKinect Project. http://www.openkinect.org
// *
// * Copyright (c) 2010 individual OpenKinect contributors. See the CONTRIB file
// * for details.
// *
// * This code is licensed to you under the terms of the Apache License, version
// * 2.0, or, at your option, the terms of the GNU General Public License,
// * version 2.0. See the APACHE20 and GPL2 files for the text of the licenses,
// * or the following URLs:
// * http://www.apache.org/licenses/LICENSE-2.0
// * http://www.gnu.org/licenses/gpl-2.0.txt
// *
// * If you redistribute this file in source form, modified or unmodified, you
// * may:
// *   1) Leave this header intact and distribute it under the same terms,
// *      accompanying it with the APACHE20 and GPL20 files, or
// *   2) Delete the Apache 2.0 clause and accompany it with the GPL2 file, or
// *   3) Delete the GPL v2 clause and accompany it with the APACHE20 file
// * In all cases you must keep the copyright notice intact and include a copy
// * of the CONTRIB file.
// *
// * Binary distributions must follow the binary distribution requirements of
// * either License.
// */

#include <cstdlib>
#include <iostream>
#include <vector>
#include <libfreenect.hpp>

#include <GL/glut.h>

//class Mutex
//{
//public:
//    Mutex()
//    {
//        pthread_mutex_init(&m_mutex, NULL);
//    }
//
//    void lock()
//    {
//        pthread_mutex_lock(&m_mutex);
//    }
//
//    void unlock()
//    {
//        pthread_mutex_unlock(&m_mutex);
//    }
//
//    class ScopedLock
//    {
//    public:
//        ScopedLock(Mutex &mutex) : _mutex(mutex)
//        {
//            _mutex.lock();
//        }
//
//        ~ScopedLock()
//        {
//            _mutex.unlock();
//        }
//
//    private:
//        Mutex &_mutex;
//    };
//
//private:
//    pthread_mutex_t m_mutex;
//};

//
//class MyFreenectDevice : public Freenect::FreenectDevice
//{
//public:
//    MyFreenectDevice(freenect_context *_ctx, int _index)
//            : Freenect::FreenectDevice(_ctx, _index),
//              m_buffer_video(freenect_find_video_mode(FREENECT_RESOLUTION_MEDIUM, FREENECT_VIDEO_RGB).bytes),
//              m_buffer_depth(freenect_find_depth_mode(FREENECT_RESOLUTION_MEDIUM, FREENECT_DEPTH_REGISTERED).bytes / 2),
//              m_new_rgb_frame(false), m_new_depth_frame(false)
//    {
//        setDepthFormat(FREENECT_DEPTH_REGISTERED);
//    }
//
//    // Do not call directly, even in child
//    void VideoCallback(void *_rgb, uint32_t timestamp)
//    {
//        Mutex::ScopedLock lock(m_rgb_mutex);
//        uint8_t* rgb = static_cast<uint8_t*>(_rgb);
//        copy(rgb, rgb+getVideoBufferSize(), m_buffer_video.begin());
//        m_new_rgb_frame = true;
//    }
//
//    // Do not call directly, even in child
//    void DepthCallback(void *_depth, uint32_t timestamp)
//    {
//        Mutex::ScopedLock lock(m_depth_mutex);
//        uint16_t* depth = static_cast<uint16_t*>(_depth);
//        copy(depth, depth+getDepthBufferSize()/2, m_buffer_depth.begin());
//        m_new_depth_frame = true;
//    }
//
//    bool getRGB(std::vector<uint8_t> &buffer)
//    {
//        Mutex::ScopedLock lock(m_rgb_mutex);
//
//        if (!m_new_rgb_frame)
//            return false;
//
//        buffer.swap(m_buffer_video);
//        m_new_rgb_frame = false;
//
//        return true;
//    }
//
//    bool getDepth(std::vector<uint16_t> &buffer)
//    {
//        Mutex::ScopedLock lock(m_depth_mutex);
//
//        if (!m_new_depth_frame)
//            return false;
//
//        buffer.swap(m_buffer_depth);
//        m_new_depth_frame = false;
//
//        return true;
//    }
//
//private:
//    Mutex m_rgb_mutex;
//    Mutex m_depth_mutex;
//    std::vector<uint8_t> m_buffer_video;
//    std::vector<uint16_t> m_buffer_depth;
//    bool m_new_rgb_frame;
//    bool m_new_depth_frame;
//};
////
////
//Freenect::Freenect freenect;
//MyFreenectDevice* device;
//
//int window(0);                // Glut window identifier
//int mx = -1, my = -1;         // Prevous mouse coordinates
//float anglex = 0, angley = 0; // Panning angles
//float zoom = 1;               // Zoom factor
//bool color = true;            // Flag to indicate to use of color in the cloud
//
//
//void DrawGLScene()
//{
//    static std::vector<uint8_t> rgb(640*480*3);
//    static std::vector<uint16_t> depth(640*480);
//
//    device->getRGB(rgb);
//    device->getDepth(depth);
//
//    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
//
//    glPointSize(1.0f);
//
//    glBegin(GL_POINTS);
//
//    if (!color) glColor3ub(255, 255, 255);
//    for (int i = 0; i < 480*640; ++i)
//    {
//        if (color)
//            glColor3ub( rgb[3*i+0],    // R
//                        rgb[3*i+1],    // G
//                        rgb[3*i+2] );  // B
//
//        float f = 595.f;
//        // Convert from image plane coordinates to world coordinates
//        glVertex3f( (i%640 - (640-1)/2.f) * depth[i] / f,  // X = (x - cx) * d / fx
//                    (i/640 - (480-1)/2.f) * depth[i] / f,  // Y = (y - cy) * d / fy
//                    depth[i] );                            // Z = d
//    }
//
//    glEnd();
//
//    // Draw the world coordinate frame
//    glLineWidth(2.0f);
//    glBegin(GL_LINES);
//    glColor3ub(255, 0, 0);  // X-axis
//    glVertex3f(  0, 0, 0);
//    glVertex3f( 50, 0, 0);
//    glColor3ub(0, 255, 0);  // Y-axis
//    glVertex3f(0,   0, 0);
//    glVertex3f(0,  50, 0);
//    glColor3ub(0, 0, 255);  // Z-axis
//    glVertex3f(0, 0,   0);
//    glVertex3f(0, 0,  50);
//    glEnd();
//
//    // Place the camera
//    glMatrixMode(GL_MODELVIEW);
//    glLoadIdentity();
//    glScalef(zoom, zoom, 1);
//    gluLookAt( -7*anglex, -7*angley, -1000.0,
//               0.0,       0.0,  2000.0,
//               0.0,      -1.0,     0.0 );
//
//    glutSwapBuffers();
//}
//
//
//void keyPressed(unsigned char key, int x, int y)
//{
//    switch (key)
//    {
//        case  'C':
//        case  'c':
//            color = !color;
//            break;
//
//        case  'Q':
//        case  'q':
//        case 0x1B:  // ESC
//            glutDestroyWindow(window);
//            device->stopDepth();
//            device->stopVideo();
//            exit(0);
//    }
//}

//
//void mouseMoved(int x, int y)
//{
//    if (mx >= 0 && my >= 0)
//    {
//        anglex += x - mx;
//        angley += y - my;
//    }
//
//    mx = x;
//    my = y;
//}
//
//
//void mouseButtonPressed(int button, int state, int x, int y)
//{
//    if (state == GLUT_DOWN)
//    {
//        switch (button)
//        {
//            case GLUT_LEFT_BUTTON:
//                mx = x;
//                my = y;
//                break;
//
//            case 3:
//                zoom *= 1.2f;
//                break;
//
//            case 4:
//                zoom /= 1.2f;
//                break;
//        }
//    }
//    else if (state == GLUT_UP && button == GLUT_LEFT_BUTTON)
//    {
//        mx = -1;
//        my = -1;
//    }
//}
//
//
//void resizeGLScene(int width, int height)
//{
//    glViewport(0, 0, width, height);
//    glMatrixMode(GL_PROJECTION);
//    glLoadIdentity();
//    gluPerspective(50.0, (float)width / height, 900.0, 11000.0);
//
//    glMatrixMode(GL_MODELVIEW);
//}
//
//
//void idleGLScene()
//{
//    glutPostRedisplay();
//}
//
//
//void printInfo()
//{
//    std::cout << "\nAvailable Controls:"              << std::endl;
//    std::cout << "==================="                << std::endl;
//    std::cout << "Rotate       :   Mouse Left Button" << std::endl;
//    std::cout << "Zoom         :   Mouse Wheel"       << std::endl;
//    std::cout << "Toggle Color :   C"                 << std::endl;
//    std::cout << "Quit         :   Q or Esc\n"        << std::endl;
//}

//#include "sensor.h"
//
//#include <thread>
//
//
//#include "vecTest.h"
//
//#include <iostream>
//#include <vector>
//#include <Eigen/Core>
//
//using namespace std;
//using namespace Eigen;
//
//#define SPACE_DIM_X 10240
//#define SPACE_DIM_Y 10240
//#define SPACE_DIM_Z 10240
//
//#define OFFSET_X 2000.0f
//#define OFFSET_Y 2000.0f
//#define OFFSET_Z 2000.0f
//
//#define BRICK_LENGTH_RESOLUTION_X 40
//#define BRICK_LENGTH_RESOLUTION_Y 40
//#define BRICK_LENGTH_RESOLUTION_Z 40
//
//unsigned int divide_x_num=SPACE_DIM_X/BRICK_LENGTH_RESOLUTION_X;
//unsigned int divide_y_num=SPACE_DIM_Y/BRICK_LENGTH_RESOLUTION_Y;
//unsigned int divide_z_num=SPACE_DIM_Z/BRICK_LENGTH_RESOLUTION_Z;
//
//uint64_t
//getIndex(const Vector3f& v) {
//    Vector3f transformed=Vector3f(v.x()+OFFSET_X,v.y()+OFFSET_Y,v.z()+OFFSET_Z);
//    uint64_t ret=
//            (uint64_t)divide_x_num*divide_y_num*((uint64_t)transformed.z()/BRICK_LENGTH_RESOLUTION_Z)+
//            (uint64_t)divide_x_num*((uint64_t)(transformed.y()/BRICK_LENGTH_RESOLUTION_Y))+
//            (uint64_t)(transformed.x()/BRICK_LENGTH_RESOLUTION_X);
//    return ret;
//}
//
//Vector4f
//getPosition(const uint64_t idx) {
//    Vector4f f;
//    uint64_t temp=idx;
//    f.z()=BRICK_LENGTH_RESOLUTION_Z*(temp/(divide_x_num*divide_y_num))-OFFSET_Z;
//    temp-=(uint64_t)divide_x_num*divide_y_num*((uint64_t)(f.z()+OFFSET_Z)/BRICK_LENGTH_RESOLUTION_Z);
//    f.y()=(float)BRICK_LENGTH_RESOLUTION_Y*((uint64_t)temp/divide_x_num)-OFFSET_Y;
//    temp-=(uint64_t)divide_x_num*((uint64_t)((f.y()+OFFSET_Y)/BRICK_LENGTH_RESOLUTION_Y));
//    f.x()=(float)BRICK_LENGTH_RESOLUTION_X*temp-OFFSET_X;
//    f.w()=1.0f;
//    return f;
//}
//
//
//int main(int argc, char **argv)
//{
////    device = &freenect.createDevice<MyFreenectDevice>(0);
////    device->startVideo();
////    device->startDepth();
////
////    glutInit(&argc, argv);
////
////    glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE | GLUT_DEPTH);
////    glutInitWindowSize(640, 480);
////    glutInitWindowPosition(0, 0);
////
////    window = glutCreateWindow("LibFreenect");
////    glClearColor(0.45f, 0.45f, 0.45f, 0.0f);
////
////    glEnable(GL_DEPTH_TEST);
////    glEnable(GL_ALPHA_TEST);
////    glAlphaFunc(GL_GREATER, 0.0f);
////
////    glMatrixMode(GL_PROJECTION);
////    gluPerspective(50.0, 1.0, 900.0, 11000.0);
////
////    glutDisplayFunc(&DrawGLScene);
////    glutIdleFunc(&idleGLScene);
////    glutReshapeFunc(&resizeGLScene);
////    glutKeyboardFunc(&keyPressed);
////    glutMotionFunc(&mouseMoved);
////    glutMouseFunc(&mouseButtonPressed);
////
////    printInfo();
////
////    glutMainLoop();
//
////        sensor* sensor_=sensor::createSensor();
////        cv::Mat rgb;
////        cv::Mat depth;
////        sensor_->getData(rgb,depth);
////        cv::imshow("123",rgb);
////        cv::imshow("456",depth);
////
////        for(int i=0;i<200;i++){
////            std::cout<<depth.at<ushort>(i,i)<<std::endl;
////        }
////        cv::waitKey(0);
////    vecTest *v=new vecTest();
////    vector<float>* copied=v->getArr();
////    (*copied)[0]=0;
////    v->printAll();
//
//
////    vector<float> testarr=vector<float>(20,2);
////    testarr.reserve(30);
////    for(auto it=testarr.begin();it!=testarr.end();it++)
////        std::cout<<*it<<" ";
////    Vector3f o(120.0f,2000.0f,2000.0f);
////    uint64_t idx=getIndex(o);
////    Vector4f t=getPosition(idx);
////    Vector3f tt=t.block<3,1>(0,0);
////    std::cout<<t.x()<<" "<<t.y()<<" "<<t.z()<<endl;
////    std::cout<<idx<<std::endl;
//
//
////    std::thread t2(f1, 10); // pass by value
////    std::cout<<"main end";
////    t2.detach();
//    return 0;
//}
